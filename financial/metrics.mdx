---
title: Key Performance Indicators
description: "Performance metrics and measurement framework"
---

## Platform Performance & Adoption

<CardGroup cols={2}>
  <Card title="Audit Completion Rate" icon="check-circle">
    Percentage of started audits successfully completed
  </Card>
  <Card title="Time-to-Insight" icon="clock">
    Average time from audit submission to PDF/report generation
  </Card>
  <Card title="Platform Uptime" icon="server">
    NeatAudit, NeatLM, and Neat Portal uptime (target: >99.8%)
  </Card>
  <Card title="Confidence Score" icon="gauge">
    Alignment between system-generated readiness and outcomes
  </Card>
</CardGroup>

## Client Impact & Retention

<CardGroup cols={2}>
  <Card title="Client NPS" icon="star">
    Net Promoter Score post-audit and post-implementation
  </Card>
  <Card title="Roadmap Acceptance" icon="check">
    Percentage of audits leading to paid roadmap delivery
  </Card>
  <Card title="Deployment Success" icon="rocket">
    Percentage of projects delivered on-time and to specification
  </Card>
  <Card title="Repeat Engagements" icon="rotate">
    Number of clients returning for additional automation scopes
  </Card>
</CardGroup>

## Learning & Capability Development

<CardGroup cols={2}>
  <Card title="Portal Engagement" icon="users">
    Monthly active users in Neat Portal
  </Card>
  <Card title="Course Completion" icon="graduation-cap">
    Percentage of SMEs finishing education tracks (Target: 40%)
  </Card>
  <Card title="Content Relevance" icon="bullseye">
    SME feedback rating on curriculum applicability
  </Card>
</CardGroup>

## Operational & System Intelligence

<CardGroup cols={2}>
  <Card title="Flywheel Efficiency" icon="arrows-spin">
    Percentage of audits contributing to improved prompts (Target: 85%)
  </Card>
  <Card title="Flag Detection" icon="flag">
    Precision of internal signal triggers
  </Card>
  <Card title="LLM Stability" icon="check-double">
    Percentage of reports passing validation (Target: >95%)
  </Card>
</CardGroup>

## Capture Architecture

### Time & Performance Metrics

<Steps>
  **Time-to-Insight**
  - Captured via Make automation timestamps
  - Measures platform speed and LLM efficiency
  
  **Audit Completion Rate**
  - Tracked via Portal session logs
  - Assesses user experience and funnel health
  
  **Confidence Score Accuracy**
  - Post-roadmap SME rating vs. audit prediction
  - Validates NeatLM precision
</Steps>

### Process & Quality Metrics

<Steps>
  **Prompt Stability Rate**
  - JSON structure checks and retry flagging
  - Tracks output integrity
  
  **Roadmap Acceptance Rate**
  - CRM and Airtable milestone tracking
  - Indicates audit quality
  
  **Deployment Success Rate**
  - QA completion + milestone verification
  - Ensures implementation quality
</Steps>

### Engagement Metrics

<CardGroup cols={2}>
  <Card title="Portal Analytics" icon="chart-simple">
    - Monthly active users
    - Session length
    - Module completion
  </Card>
  <Card title="Content Metrics" icon="book">
    - Module tracking
    - Completion certification
    - Relevance ratings
  </Card>
</CardGroup>

### System Performance

<CardGroup cols={2}>
  <Card title="Flywheel Metrics" icon="gear">
    - Tag logic contributions
    - Content segmentation
    - Schema updates
  </Card>
  <Card title="LLM Performance" icon="microchip">
    - Flag detection accuracy
    - Prompt version tracking
    - Output structure match
  </Card>
</CardGroup>

<Note>
These metrics are systematically captured through our automated workflows, providing real-time visibility into platform performance and business impact.
</Note>